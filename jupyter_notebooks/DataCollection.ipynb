{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection for Mildew Detection in Cherry Leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "* Fetch the dataset of cherry leaf images from the provided source and examine its structure.\n",
    "* Save the raw image data in an organized directory structure for easy access in later stages.\n",
    "\n",
    "## Inputs\n",
    "* Dataset URL or access key if the dataset is hosted on platforms like Kaggle.\n",
    "\n",
    "## Outputs\n",
    "* Directory structure containing the raw dataset divided into training, validation, and test sets.\n",
    "\n",
    "## Additional Comments\n",
    "* Ensure compliance with any data use agreements or NDAs associated with the dataset.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r \"/Users/jordanfletorides/Desktop/github repos/ml-mildew-detector/requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir\n",
    "\n",
    "# Changing file permissions (for Unix-like OS)\n",
    "! chmod -R u+w inputs/cherry_leaves_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install kaggle package\n",
    "%pip install kaggle==1.5.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below **to change the Kaggle configuration directory to the current working directory and set permissions for the Kaggle authentication JSON**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
    "! chmod 600 kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the dataset path from the [Kaggle URL](https://www.kaggle.com/datasets/codeinstitute/cherry-leaves/data). When you are viewing the dataset at Kaggle, check what is after https://www.kaggle.com/ (in some cases kaggle.com/datasets). You should copy that at KaggleDatasetPath.\n",
    "* Set your destination folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the Kaggle Dataset and Download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KaggleDatasetPath = \"codeinstitute/cherry-leaves/data\"\n",
    "DestinationFolder = \"inputs/cherry_leaves_dataset\"\n",
    "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip the downloaded file, and delete the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(DestinationFolder + '/cherry-leaves.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(DestinationFolder)\n",
    "\n",
    "os.remove(DestinationFolder + '/cherry-leaves.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and remove non-image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_non_images(directory_path):\n",
    "    valid_extensions = ('.png', '.jpg', '.jpeg')  # Valid image file extensions\n",
    "    \n",
    "    # Ensure the base directory exists and is a directory\n",
    "    if not os.path.isdir(directory_path):\n",
    "        print(f\"Provided path '{directory_path}' is not a directory.\")\n",
    "        return\n",
    "\n",
    "    subdirectories = [d for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))]\n",
    "\n",
    "    for subfolder in subdirectories:\n",
    "        path = os.path.join(directory_path, subfolder)\n",
    "        files_in_subfolder = os.listdir(path)\n",
    "\n",
    "        image_count, non_image_count = 0, 0\n",
    "        for file in files_in_subfolder:\n",
    "            if file.lower().endswith(valid_extensions):\n",
    "                image_count += 1\n",
    "            else:\n",
    "                non_image_path = os.path.join(path, file)  # Construct full file path\n",
    "                try:\n",
    "                    os.remove(non_image_path)  # Attempt to remove the non-image file\n",
    "                    non_image_count += 1\n",
    "                except PermissionError:\n",
    "                    print(f\"Permission denied: {non_image_path}\")\n",
    "\n",
    "        print(f\"Subfolder '{subfolder}': {image_count} images, {non_image_count} non-images removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'directory_path' is the parameter name used in the revised function 'clear_non_images'\n",
    "clear_non_images(directory_path='inputs/cherry_leaves_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train validation test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def distribute_dataset_images(dataset_path, train_ratio, validation_ratio, test_ratio):\n",
    "    \"\"\"\n",
    "    Distribute images across train, validation, and test folders based on specified ratios.\n",
    "    \n",
    "    Args:\n",
    "    dataset_path (str): The directory containing the class folders.\n",
    "    train_ratio (float): The proportion of images to be used for the training set.\n",
    "    validation_ratio (float): The proportion of images to be used for the validation set.\n",
    "    test_ratio (float): The proportion of images to be used for the test set.\n",
    "    \"\"\"\n",
    "    # Check if ratios sum to 1\n",
    "    if train_ratio + validation_ratio + test_ratio != 1.0:\n",
    "        print(\"The sum of ratios must be 1.0.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        categories = [category for category in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, category))]\n",
    "        \n",
    "        # Check if 'test' directory exists to avoid recreating structure\n",
    "        if not 'test' in categories:\n",
    "            # Creating directories for each subset and category\n",
    "            for subset in ['train', 'validation', 'test']:\n",
    "                subset_path = os.path.join(dataset_path, subset)\n",
    "                for category in categories:\n",
    "                    dir_path = os.path.join(subset_path, category)\n",
    "                    if not os.path.exists(dir_path):\n",
    "                        os.makedirs(dir_path, exist_ok=True)\n",
    "            \n",
    "            # Distributing files\n",
    "            for category in categories:\n",
    "                files = os.listdir(os.path.join(dataset_path, category))\n",
    "                random.shuffle(files)\n",
    "                \n",
    "                train_end = int(len(files) * train_ratio)\n",
    "                validation_end = train_end + int(len(files) * validation_ratio)\n",
    "\n",
    "                train_files = files[:train_end]\n",
    "                validation_files = files[train_end:validation_end]\n",
    "                test_files = files[validation_end:]\n",
    "\n",
    "                # Function to move files to their new location\n",
    "                def move_files(files, subset):\n",
    "                    for file_name in files:\n",
    "                        source_path = os.path.join(dataset_path, category, file_name)\n",
    "                        destination_path = os.path.join(dataset_path, subset, category, file_name)\n",
    "                        shutil.move(source_path, destination_path)\n",
    "                \n",
    "                # Moving files to respective directories\n",
    "                move_files(train_files, 'train')\n",
    "                move_files(validation_files, 'validation')\n",
    "                move_files(test_files, 'test')\n",
    "                \n",
    "                # Remove original category directory if empty\n",
    "                if os.listdir(os.path.join(dataset_path, category)) == []:\n",
    "                    os.rmdir(os.path.join(dataset_path, category))\n",
    "\n",
    "        print(\"Dataset successfully distributed into train, validation, and test sets.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conventionally,\n",
    "* The training set is divided into a 0.70 ratio of data.\n",
    "* The validation set is divided into a 0.10 ratio of data.\n",
    "* The test set is divided into a 0.20 ratio of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribute_dataset_images(dataset_path=\"inputs/cherry_leaves_dataset\",\n",
    "                          train_ratio=0.7,\n",
    "                          validation_ratio=0.1,\n",
    "                          test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
